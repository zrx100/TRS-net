{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Relevant libraries and functions\n",
    "from __future__ import print_function\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import numpy as np, h5py\n",
    "import os, time, sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization, Convolution2D, Input, SpatialDropout2D, UpSampling2D, MaxPooling2D, concatenate\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import Dense, Dropout, Conv1D, Input, Conv2D, add, Conv3D, Reshape\n",
    "from keras.callbacks import History, EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from itertools import cycle\n",
    "from sklearn import metrics\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, SeparableConv2D, Conv2DTranspose\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.11482575]\n",
      "  [0.89438283]\n",
      "  [1.0404357 ]\n",
      "  ...\n",
      "  [0.2057458 ]\n",
      "  [0.14423156]\n",
      "  [1.0757622 ]]\n",
      "\n",
      " [[0.9017317 ]\n",
      "  [0.16931212]\n",
      "  [0.92924285]\n",
      "  ...\n",
      "  [0.9115608 ]\n",
      "  [0.18192984]\n",
      "  [0.17215416]]\n",
      "\n",
      " [[1.043794  ]\n",
      "  [0.14339657]\n",
      "  [0.9749211 ]\n",
      "  ...\n",
      "  [0.15237416]\n",
      "  [1.0376008 ]\n",
      "  [1.019669  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.88890064]\n",
      "  [0.19930372]\n",
      "  [1.0388055 ]\n",
      "  ...\n",
      "  [0.1750693 ]\n",
      "  [1.0702246 ]\n",
      "  [0.931305  ]]\n",
      "\n",
      " [[0.21018508]\n",
      "  [1.0240307 ]\n",
      "  [0.16440907]\n",
      "  ...\n",
      "  [0.13124827]\n",
      "  [0.17233028]\n",
      "  [0.16692233]]\n",
      "\n",
      " [[1.0052361 ]\n",
      "  [0.90126127]\n",
      "  [0.9253435 ]\n",
      "  ...\n",
      "  [1.0789585 ]\n",
      "  [0.90918005]\n",
      "  [0.97234493]]]\n"
     ]
    }
   ],
   "source": [
    "#f_data =  '/gs/home/wenjiao/zrx-2DGP/2DCNN-sin/pydata/trainsingle'\n",
    "f_data = '.\\trainsin'\n",
    "stacks = os.listdir(f_data)\n",
    "numS = int(len(stacks))\n",
    "\n",
    "nTG = 90 # Number of time-points\n",
    "xX = 100\n",
    "tpsfD = np.ndarray(\n",
    "        (numS, int(nTG), int(xX),  int(1)), dtype=np.float32  \n",
    "        )\n",
    "t1 = np.ndarray(\n",
    "        (numS, int(xX), int(1)), dtype=np.float32\n",
    "        )\n",
    "i = 0;\n",
    "for d in stacks:\n",
    "    # Save values to respective mapping\n",
    "    f = h5py.File(os.path.join(f_data,d),'r') \n",
    "    tpsfD[i,:,:,0] = f.get('sigD_a')\n",
    "    f = h5py.File(os.path.join(f_data,d),'r') \n",
    "    t1[i,:] = f.get('t1_a')\n",
    "    i = i + 1\n",
    "    \n",
    "tpsfD[np.isnan(tpsfD)]=0\n",
    "    \n",
    "tpsfD =  np.moveaxis(tpsfD, 1, -2)\n",
    "\n",
    "def norm(data):\n",
    "    _range = np.max(data) - np.min(data)\n",
    "    return data / _range\n",
    "t1=norm(t1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 100, 90, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure TPSF voxel shape is correct dimensionality (# samples, x, y, time-points, 1)\n",
    "tpsfD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant resblock functions (Keras API)\n",
    "def resblock_2D(num_filters, size_filter, x):\n",
    "    Fx = Conv2D(num_filters, size_filter, padding='same', activation=None)(x)\n",
    "    Fx = Activation('relu')(Fx)\n",
    "    Fx = Conv2D(num_filters, size_filter, padding='same', activation=None)(Fx)\n",
    "    output = add([Fx, x])\n",
    "    output = Activation('relu')(output)\n",
    "    return output\n",
    "\n",
    "def resblock_2D_BN(num_filters, size_filter, x):\n",
    "    Fx = Conv2D(num_filters, size_filter, padding='same', activation=None)(x)\n",
    "    Fx = BatchNormalization()(Fx)\n",
    "    Fx = Activation('relu')(Fx)\n",
    "    Fx = Conv2D(num_filters, size_filter, padding='same', activation=None)(Fx)\n",
    "    Fx = BatchNormalization()(Fx)\n",
    "    output = add([Fx, x])\n",
    "    #output = BatchNormalization()(output)\n",
    "    output = Activation('relu')(output)\n",
    "    return output\n",
    "\n",
    "def resblock_3D_BN(num_filters, size_filter, x):\n",
    "    Fx = Conv3D(num_filters, size_filter, padding='same', activation=None)(x)\n",
    "    Fx = BatchNormalization()(Fx)\n",
    "    Fx = Activation('relu')(Fx)\n",
    "    Fx = Conv3D(num_filters, size_filter, padding='same', activation=None)(Fx)\n",
    "    Fx = BatchNormalization()(Fx)\n",
    "    output = add([Fx, x])\n",
    "    #output = BatchNormalization()(output)\n",
    "    output = Activation('relu')(output)\n",
    "    return output\n",
    "\n",
    "def xCeptionblock_2D_BN(num_filters, size_filter, x):\n",
    "    Fx = SeparableConv2D(num_filters, size_filter, padding='same', activation=None)(x)\n",
    "    Fx = BatchNormalization()(Fx)\n",
    "    Fx = Activation('relu')(Fx)\n",
    "    Fx = SeparableConv2D(num_filters, size_filter, padding='same', activation=None)(Fx)\n",
    "    Fx = BatchNormalization()(Fx)\n",
    "    output = add([Fx, x])\n",
    "    output = Activation('relu')(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelD = None\n",
    "xX = 100;\n",
    "\n",
    "\n",
    "t_data = Input(shape=(xX,90,1))\n",
    "tpsf = t_data\n",
    "\n",
    "# # # # # # # # 2D-Model # # # # # # # #\n",
    "\n",
    "tpsf = Conv2D(10,kernel_size=(1,10),strides=(1,5), padding='same', activation=None, data_format=\"channels_last\")(tpsf)\n",
    "tpsf = BatchNormalization()(tpsf)\n",
    "tpsf = Activation('relu')(tpsf)\n",
    "\n",
    "\n",
    "tpsf = Conv2D(128,1, padding='same', activation=None, data_format=\"channels_last\")(tpsf)\n",
    "tpsf = BatchNormalization()(tpsf)\n",
    "tpsf = Activation('relu')(tpsf)\n",
    "tpsf = Conv2D(128,1, padding='same', activation=None, data_format=\"channels_last\")(tpsf)\n",
    "tpsf = BatchNormalization()(tpsf)\n",
    "tpsf = Activation('relu')(tpsf)\n",
    "tpsf = resblock_2D_BN(128, 1,tpsf)\n",
    "tpsf = resblock_2D_BN(128, 1,tpsf)\n",
    "tpsf = Reshape((xX,2304))(tpsf)\n",
    "\n",
    "# Short-lifetime branch\n",
    "imgT1 = Dense(64, activation=None)(tpsf)\n",
    "imgT1 = BatchNormalization()(imgT1)\n",
    "imgT1 = Activation('relu')(imgT1)\n",
    "imgT1 = Dense(32, activation=None)(imgT1)\n",
    "imgT1 = BatchNormalization()(imgT1)\n",
    "imgT1 = Activation('relu')(imgT1)\n",
    "imgT1 = Dense(1, activation=None)(imgT1)\n",
    "imgT1 = Activation('relu')(imgT1)\n",
    "\n",
    "# Long-lifetime branch\n",
    "imgT2 = Dense(64, activation=None)(tpsf)\n",
    "imgT2 = BatchNormalization()(imgT2)\n",
    "imgT2 = Activation('relu')(imgT2)\n",
    "imgT2 = Dense(32, activation=None)(imgT2)\n",
    "imgT2 = BatchNormalization()(imgT2)\n",
    "imgT2 = Activation('relu')(imgT2)\n",
    "imgT2 = Dense(1, activation=None)(imgT2)\n",
    "imgT2 = Activation('relu')(imgT2)\n",
    "\n",
    "# Amplitude-Ratio branch\n",
    "imgTR = Dense(64, activation=None)(tpsf)\n",
    "imgTR = BatchNormalization()(imgTR)\n",
    "imgTR = Activation('relu')(imgTR)\n",
    "imgTR = Dense(32, activation=None)(imgTR)\n",
    "imgTR = BatchNormalization()(imgTR)\n",
    "imgTR = Activation('relu')(imgTR)\n",
    "imgTR = Dense(1, activation=None)(imgTR) \n",
    "imgTR = Activation('relu')(imgTR)\n",
    "\n",
    "\n",
    "modelD = Model(inputs=[t_data], outputs=[imgT1])\n",
    "rmsprop = RMSprop(lr=1e-5)\n",
    "\n",
    "modelD.compile(loss='mse',\n",
    "              optimizer= 'adam',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 18s 693ms/step - loss: 0.1714 - mae: 0.2790 - val_loss: 0.4603 - val_mae: 0.5314\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 17s 726ms/step - loss: 0.0157 - mae: 0.1083 - val_loss: 0.4249 - val_mae: 0.4949\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 19s 807ms/step - loss: 0.0134 - mae: 0.0981 - val_loss: 0.3822 - val_mae: 0.4550\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 19s 809ms/step - loss: 0.0103 - mae: 0.0838 - val_loss: 0.3588 - val_mae: 0.4376\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 18s 770ms/step - loss: 0.0088 - mae: 0.0754 - val_loss: 0.3179 - val_mae: 0.4141\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 18s 774ms/step - loss: 0.0084 - mae: 0.0725 - val_loss: 0.2785 - val_mae: 0.4064\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 18s 766ms/step - loss: 0.0079 - mae: 0.0691 - val_loss: 0.2398 - val_mae: 0.4123\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 18s 758ms/step - loss: 0.0074 - mae: 0.0666 - val_loss: 0.2218 - val_mae: 0.4228\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 19s 775ms/step - loss: 0.0067 - mae: 0.0633 - val_loss: 0.2141 - val_mae: 0.4140\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 18s 770ms/step - loss: 0.0059 - mae: 0.0595 - val_loss: 0.2164 - val_mae: 0.3884\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 18s 769ms/step - loss: 0.0051 - mae: 0.0553 - val_loss: 0.2236 - val_mae: 0.3797\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 18s 764ms/step - loss: 0.0044 - mae: 0.0507 - val_loss: 0.2297 - val_mae: 0.3687\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 18s 768ms/step - loss: 0.0045 - mae: 0.0510 - val_loss: 0.2203 - val_mae: 0.3595\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 20s 857ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.2085 - val_mae: 0.3497\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 18s 767ms/step - loss: 0.0035 - mae: 0.0444 - val_loss: 0.1979 - val_mae: 0.3573\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 19s 794ms/step - loss: 0.0037 - mae: 0.0457 - val_loss: 0.1332 - val_mae: 0.2924\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 20s 823ms/step - loss: 0.0033 - mae: 0.0435 - val_loss: 0.0904 - val_mae: 0.2451\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 19s 791ms/step - loss: 0.0033 - mae: 0.0428 - val_loss: 0.0647 - val_mae: 0.2039\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 19s 809ms/step - loss: 0.0032 - mae: 0.0430 - val_loss: 0.0412 - val_mae: 0.1638\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 19s 781ms/step - loss: 0.0030 - mae: 0.0406 - val_loss: 0.0203 - val_mae: 0.1168\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 19s 772ms/step - loss: 0.0030 - mae: 0.0400 - val_loss: 0.0144 - val_mae: 0.1001\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 19s 780ms/step - loss: 0.0028 - mae: 0.0396 - val_loss: 0.0076 - val_mae: 0.0702\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 20s 820ms/step - loss: 0.0031 - mae: 0.0415 - val_loss: 0.0053 - val_mae: 0.0579\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 19s 773ms/step - loss: 0.0027 - mae: 0.0384 - val_loss: 0.0038 - val_mae: 0.0492\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 19s 795ms/step - loss: 0.0027 - mae: 0.0383 - val_loss: 0.0152 - val_mae: 0.0977\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 19s 773ms/step - loss: 0.0030 - mae: 0.0417 - val_loss: 0.0111 - val_mae: 0.0769\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 18s 767ms/step - loss: 0.0027 - mae: 0.0385 - val_loss: 0.0041 - val_mae: 0.0509\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 19s 814ms/step - loss: 0.0025 - mae: 0.0359 - val_loss: 0.0029 - val_mae: 0.0418\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 20s 815ms/step - loss: 0.0040 - mae: 0.0481 - val_loss: 0.0185 - val_mae: 0.1206\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 18s 765ms/step - loss: 0.0039 - mae: 0.0479 - val_loss: 0.0082 - val_mae: 0.0760\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 18s 770ms/step - loss: 0.0034 - mae: 0.0445 - val_loss: 0.0064 - val_mae: 0.0663\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 19s 787ms/step - loss: 0.0031 - mae: 0.0427 - val_loss: 0.0055 - val_mae: 0.0605\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 18s 769ms/step - loss: 0.0028 - mae: 0.0386 - val_loss: 0.0062 - val_mae: 0.0648\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 19s 777ms/step - loss: 0.0026 - mae: 0.0373 - val_loss: 0.0042 - val_mae: 0.0517\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 19s 799ms/step - loss: 0.0025 - mae: 0.0375 - val_loss: 0.0031 - val_mae: 0.0440\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 18s 768ms/step - loss: 0.0024 - mae: 0.0358 - val_loss: 0.0028 - val_mae: 0.0399\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 18s 767ms/step - loss: 0.0024 - mae: 0.0354 - val_loss: 0.0026 - val_mae: 0.0389\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 19s 795ms/step - loss: 0.0024 - mae: 0.0363 - val_loss: 0.0031 - val_mae: 0.0424\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 18s 763ms/step - loss: 0.0026 - mae: 0.0377 - val_loss: 0.0028 - val_mae: 0.0410\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 18s 762ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 0.0029 - val_mae: 0.0417\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 18s 764ms/step - loss: 0.0024 - mae: 0.0351 - val_loss: 0.0027 - val_mae: 0.0383\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 20s 834ms/step - loss: 0.0025 - mae: 0.0373 - val_loss: 0.0049 - val_mae: 0.0547\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 19s 781ms/step - loss: 0.0029 - mae: 0.0406 - val_loss: 0.0052 - val_mae: 0.0562\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 19s 811ms/step - loss: 0.0026 - mae: 0.0372 - val_loss: 0.0024 - val_mae: 0.0363\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 19s 776ms/step - loss: 0.0023 - mae: 0.0342 - val_loss: 0.0022 - val_mae: 0.0339\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 18s 773ms/step - loss: 0.0023 - mae: 0.0343 - val_loss: 0.0023 - val_mae: 0.0350\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 18s 762ms/step - loss: 0.0023 - mae: 0.0339 - val_loss: 0.0027 - val_mae: 0.0387\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 18s 771ms/step - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0022 - val_mae: 0.0340\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 19s 776ms/step - loss: 0.0021 - mae: 0.0321 - val_loss: 0.0023 - val_mae: 0.0350\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 19s 784ms/step - loss: 0.0023 - mae: 0.0345 - val_loss: 0.0024 - val_mae: 0.0380\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 19s 776ms/step - loss: 0.0022 - mae: 0.0345 - val_loss: 0.0028 - val_mae: 0.0414\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 18s 765ms/step - loss: 0.0022 - mae: 0.0331 - val_loss: 0.0025 - val_mae: 0.0402\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 18s 766ms/step - loss: 0.0020 - mae: 0.0315 - val_loss: 0.0023 - val_mae: 0.0371\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 18s 764ms/step - loss: 0.0019 - mae: 0.0308 - val_loss: 0.0040 - val_mae: 0.0513\n",
      "Epoch 55/500\n",
      "24/24 [==============================] - 18s 768ms/step - loss: 0.0022 - mae: 0.0332 - val_loss: 0.0028 - val_mae: 0.0412\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 19s 778ms/step - loss: 0.0020 - mae: 0.0312 - val_loss: 0.0023 - val_mae: 0.0357\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 18s 765ms/step - loss: 0.0019 - mae: 0.0302 - val_loss: 0.0021 - val_mae: 0.0334\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 19s 774ms/step - loss: 0.0019 - mae: 0.0297 - val_loss: 0.0020 - val_mae: 0.0318\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 18s 766ms/step - loss: 0.0019 - mae: 0.0302 - val_loss: 0.0019 - val_mae: 0.0308\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 19s 808ms/step - loss: 0.0019 - mae: 0.0302 - val_loss: 0.0019 - val_mae: 0.0299\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 19s 794ms/step - loss: 0.0018 - mae: 0.0295 - val_loss: 0.0019 - val_mae: 0.0295\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 19s 789ms/step - loss: 0.0018 - mae: 0.0296 - val_loss: 0.0019 - val_mae: 0.0304\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 18s 769ms/step - loss: 0.0018 - mae: 0.0298 - val_loss: 0.0018 - val_mae: 0.0297\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 19s 792ms/step - loss: 0.0018 - mae: 0.0295 - val_loss: 0.0018 - val_mae: 0.0291\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 20s 829ms/step - loss: 0.0019 - mae: 0.0301 - val_loss: 0.0018 - val_mae: 0.0292\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 19s 779ms/step - loss: 0.0018 - mae: 0.0297 - val_loss: 0.0018 - val_mae: 0.0292\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 19s 773ms/step - loss: 0.0018 - mae: 0.0293 - val_loss: 0.0018 - val_mae: 0.0292\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 19s 786ms/step - loss: 0.0018 - mae: 0.0296 - val_loss: 0.0018 - val_mae: 0.0296\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 18s 766ms/step - loss: 0.0018 - mae: 0.0296 - val_loss: 0.0018 - val_mae: 0.0290\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 18s 765ms/step - loss: 0.0018 - mae: 0.0293 - val_loss: 0.0018 - val_mae: 0.0292\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 19s 774ms/step - loss: 0.0018 - mae: 0.0291 - val_loss: 0.0018 - val_mae: 0.0290\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 18s 763ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 0.0018 - val_mae: 0.0288\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 18s 768ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 0.0018 - val_mae: 0.0288\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 19s 780ms/step - loss: 0.0018 - mae: 0.0290 - val_loss: 0.0018 - val_mae: 0.0288\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 18s 771ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 19s 808ms/step - loss: 0.0018 - mae: 0.0291 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 19s 784ms/step - loss: 0.0018 - mae: 0.0293 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 18s 772ms/step - loss: 0.0018 - mae: 0.0291 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 18s 763ms/step - loss: 0.0018 - mae: 0.0290 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 19s 773ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 19s 773ms/step - loss: 0.0018 - mae: 0.0290 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 18s 765ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 19s 799ms/step - loss: 0.0018 - mae: 0.0293 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 19s 775ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 18s 763ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 18s 771ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 18s 760ms/step - loss: 0.0018 - mae: 0.0292 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 19s 776ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 18s 765ms/step - loss: 0.0018 - mae: 0.0292 - val_loss: 0.0018 - val_mae: 0.0287\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 18s 766ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 0.0018 - val_mae: 0.0287\n"
     ]
    }
   ],
   "source": [
    "# Setting patience (patience = 15 recommended)\n",
    "#tpsfD=tpsfD.reshape\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                              patience = 15, \n",
    "                              verbose = 0,\n",
    "                              mode = 'auto')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=10, mode='auto')\n",
    "\n",
    "fN = 'testName' # Assign some name for weights and training/validation loss curves here\n",
    "\n",
    "# Save loss curve (mse) and MAE information over all trained epochs. (monitor = '' can be changed to focus on other tau parameters)\n",
    "modelCheckPoint = ModelCheckpoint(filepath=fN+'.h5', \n",
    "                                  monitor='val_loss', \n",
    "                                  save_best_only=True, \n",
    "                                  verbose=0)\n",
    "# Train network (80/20 train/validation split, batch_size=20 recommended, nb_epoch may vary based on application)\n",
    "history = History()\n",
    "csv_logger = CSVLogger(fN+'.log')\n",
    "history = modelD.fit([tpsfD],[t1],\n",
    "          validation_split=0.2,\n",
    "          batch_size=20, epochs=500,verbose=1, shuffle=True, callbacks=[earlyStopping,csv_logger,modelCheckPoint,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.89492285]\n",
      "   [0.9109897 ]\n",
      "   [0.93316197]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.88404393]\n",
      "   [0.89082688]\n",
      "   [0.91602069]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.87657511]\n",
      "   [0.876252  ]\n",
      "   [0.88400644]]]]\n"
     ]
    }
   ],
   "source": [
    "t_data = '.\\testbi'\n",
    "#t_data = '/gs/home/wenjiao/zrx-2DGP/Group-bi/pydata/fitbi' # directory with test data\n",
    "stacksT = os.listdir(t_data)\n",
    "numT = int(len(stacksT))\n",
    "\n",
    "nTG = 90\n",
    "xX = 58\n",
    "\n",
    "\n",
    "tpsfT = np.ndarray(\n",
    "        (numT, int(nTG), int(xX),  int(1)), dtype=np.float32\n",
    "        )\n",
    "t1T = np.ndarray(\n",
    "        (numT, int(xX), int(1)), dtype=np.float32\n",
    "        )\n",
    "\n",
    "def norm(data):\n",
    "    _range = np.max(data) - np.min(data)\n",
    "    return (data - np.min(data)) / _range\n",
    "i = 0;\n",
    "\n",
    "for d in stacksT:\n",
    "    #Save values to respective mapping\n",
    "    f = h5py.File(os.path.join(t_data,d),'r') \n",
    "    tpsfT[i,:,:,0] = f.get('sigD_sin')\n",
    "    f = h5py.File(os.path.join(t_data,d),'r') \n",
    "    t1T[i,:] = f.get('t_sin')\n",
    "#tpsfT =  np.moveaxis(tpsfT,1,-2)\n",
    "tpsfT = np.moveaxis(tpsfT, 1, 2)\n",
    "tpsfT.shape\n",
    "tpsfT=tpsfT.reshape(58,90)\n",
    "b=np.zeros((42,90))\n",
    "pre=np.append(b,tpsfT)\n",
    "pre.shape\n",
    "pre=pre.reshape(1,100,90,1)\n",
    "pre.shape\n",
    "\n",
    "print(pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on test data with trained model\n",
    "testV = modelD.predict(pre)\n",
    "import pickle\n",
    "\n",
    "def save_variable(v,filename):\n",
    "        f = open(filename,'wb')\n",
    "        pickle.dump(v,f)\n",
    "        f.close()\n",
    "        return filename\n",
    "\n",
    "def load_variable(filename):\n",
    "        f=open(filename,'rb')\n",
    "        r=pickle.load(f)\n",
    "        f.close()\n",
    "        return r\n",
    "\n",
    "import joblib\n",
    "joblib.dump(testV,'smilesin2080N.pkl')\n",
    "modelD.save('smilesin2080N.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x16380ad5550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
